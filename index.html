<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ClinIQLink 2025 - LLM Lie Detector Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #ffffff;
            color: #212121;
            box-sizing: border-box;
        }
        header {
            background-color: #0071bc;
            color: white;
            padding: 15px;
            text-align: center;
        }
        main {
            padding: 10px;
        }
        h1 {
            color: white;
        }
        h2, h3 {
            color: #0071bc;
        }
        section {
            margin-bottom: 20px;
            padding: 10px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
            border-radius: 5px;
            background-color: #ffffff;
            border: 1px solid #aeb0b5;
        }
        .collapsible {
            cursor: pointer;
            padding: 10px;
            text-align: left;
            outline: none;
            font-size: 18px;
            font-weight: bold;
            border: none;
            background-color: #0071bc;
            color: white;
            margin-top: 10px;
            width: 100%;
        }
        .collapsible:after {
            content: '\002B';
            font-size: 13px;
            float: right;
        }
        .collapsible.active:after {
            content: '\2212';
        }
        .content {
            padding: 0 15px;
            display: none;
            overflow: hidden;
            background-color: #f9f9f9;
        }
        a {
            color: #0071bc;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        footer {
            background-color: #112e51;
            color: white;
            text-align: center;
            padding: 10px;
            position: relative;
            bottom: 0;
            width: 100%;
        }
        @media (max-width: 768px) {
            body {
                font-size: 14px;
            }
            header, footer {
                padding: 10px;
            }
        }
        @media (max-width: 480px) {
            body {
                font-size: 12px;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>ClinIQLink 2025 - LLM Lie Detector Test</h1>
        <p>Evaluating Internal Model Knowledge Retrieval and Hallucinations</p>
    </header>
    <main>
        <section>
            <h2>Task Overview</h2>
            <p>
                The objective of this task is to evaluate the effectiveness of generative models in producing factually accurate information. Participants will <b>submit their evaluation metrics to a leaderboard </b> using the official script provided by the organizers. The leaderboard will automatically rank submissions based on the reported results.
                
                Using a structured set of atomic question-answer pairs, the task will measure how well the models retrieve factually correct information. The benchmarking framework will pose well-defined, atomic questions to the models, requiring a single, precise response. These questions will assess the model's knowledge about fundamental medical concepts and its ability to avoid common pitfalls like hallucination or factual inaccuracies. Scoring will be based on the precision of the answers and will involve partial, full, or negative points based on accuracy. Full points will be awarded for exact or semantically equivalent answers, while incorrect answers or repeated factual errors on the same concept will result in negative scores.
                
                <b>Participants are encouraged to make their models public for transparency, but this will be optional.</b> This task focuses purely on fact retrieval and does not assess reasoning abilities like commonsense reasoning, temporal understanding, or logical consistency.
            </p>
        </section>

        <section>
            <h2>Datasets</h2>
            <p>The dataset provided for this task is a collection of factual, atomic question-answer pairs grounded in the medical domain, specifically curated to align with the knowledge level of a General Practitioner (GP) Medical Doctor. These question-answer pairs cover core medical concepts such as procedures, conditions, drugs, and diagnostics.</p>
            <ul>
                <li>
                    <strong>Short Answer:</strong><br>
                    Question:<br> <em>"What is a Laparoscopy?"</em><br>
                    Answer:<br> <em>"A minimally invasive surgical procedure that uses a camera to view the inside of the abdomen."</em>
                </li>
                <li>
                    <strong>True/False:</strong><br>
                    Question:<br> <em>"Antibiotics can treat viral infections."</em><br>
                    Answer:<br> <em>"False."</em>
                </li>
                <li>
                    <strong>List:</strong><br>
                    Question:<br> <em>"List the four chambers of the human heart."</em><br>
                    Options:<br>
                    <ul>
                        <li>A. right atrium</li>
                        <li>B. top atrium</li>
                        <li>C. right ventrical</li>
                        <li>D. bottom ventricle</li>
                        <li>E. left atrium</li>
                        <li>F. left ventricle</li>
                    </ul>
                    Answer:<br> <em>"A. right atrium, C. right ventricle, E. left atrium, F. left ventricle."</em>
                </li>
                <li>
                    <strong>Multiple Choice:</strong><br>
                    Question:<br> <em>"Which of the following is not a symptom of diabetes?"</em><br>
                    Options:<br>
                    <ul>
                        <li>A. Increased thirst</li>
                        <li>B. Frequent urination</li>
                        <li>C. Blurred vision</li>
                        <li>D. High fever</li>
                    </ul>
                    Correct Answer:<br> <em>"D. High fever"</em>
                </li>
                <li>
                    <strong>Multi-Hop Reasoning:</strong><br>
                    Question:<br> <em>"A patient presents with fatigue and shortness of breath. Lab results show low hemoglobin levels and high mean corpuscular volume (MCV). Based on these findings, what condition might the patient have, and what deficiency could be contributing to it?"</em><br>
                    Answer:<br> <em>"The patient might have megaloblastic anemia caused by a vitamin B12 deficiency."</em><br>
                    Reasoning:<br> 
                    <em>"Step 1: Fatigue and shortness of breath are symptoms of anemia. Step 2: High MCV indicates macrocytic anemia. Step 3: Macrocytic anemia is commonly caused by vitamin B12 or folate deficiency. Step 4: Conclude megaloblastic anemia due to likely vitamin B12 deficiency."</em>
                </li>
            </ul>
        </section>

        <section>
            <h2>Evaluation Metrics</h2>
            <ol>
                <li>
                    <strong>Exact Match (Full Points):</strong>
                    <ul>
                        <li><strong>Definition:</strong> Full points will be awarded if the model provides an exact match to the known ground truth answer.</li>
                        <li><strong>Example:</strong>
                            <ul>
                                <li><strong>Question:</strong> "What is Laparoscopy?"</li>
                                <li><strong>Expected Answer:</strong> "A minimally invasive surgical procedure using a camera."</li>
                                <li><strong>Model Answer:</strong> "A minimally invasive surgical procedure using a camera."</li>
                                <li><strong>Scoring:</strong> If the model returns exactly this answer, full points are awarded.</li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li>
                    <strong>Semantic Match (Full Points):</strong>
                    <ul>
                        <li><strong>Definition:</strong> Full points will also be awarded if the model returns an answer that is semantically equivalent to the ground truth, even if phrased differently (e.g., using synonyms).</li>
                        <li><strong>Example:</strong>
                            <ul>
                                <li><strong>Question:</strong> "What is Laparoscopy?"</li>
                                <li><strong>Expected Answer:</strong> "A minimally invasive surgical procedure using a camera."</li>
                                <li><strong>Model Answer:</strong> "A minimally invasive surgery with a camera."</li>
                                <li><strong>Scoring:</strong> If the model provides an equivalent meaning with different wording, it will receive full points.</li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li>
                    <strong>Partial Semantic Similarity (Partial Points):</strong>
                    <ul>
                        <li><strong>Definition:</strong> Partial points will be awarded if the model provides an answer that is semantically similar but not completely accurate or misses key details.</li>
                        <li><strong>Example:</strong>
                            <ul>
                                <li><strong>Question:</strong> "What is Laparoscopy?"</li>
                                <li><strong>Expected Answer:</strong> "A minimally invasive surgical procedure using a camera."</li>
                                <li><strong>Model Answer:</strong> "A procedure using a camera."</li>
                                <li><strong>Scoring:</strong> Since the model missed the aspect of "minimally invasive," partial points will be awarded for providing a partially correct answer.</li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li>
                    <strong>Factually Inaccurate Answers (Negative Points):</strong>
                    <ul>
                        <li><strong>Definition:</strong> Models that return incorrect answers will receive negative points. This applies if the model introduces false facts or hallucinated information.</li>
                        <li><strong>Example:</strong>
                            <ul>
                                <li><strong>Question:</strong> "Antibiotics can treat viral infections?"</li>
                                <li><strong>Expected Answer:</strong> "False"</li>
                                <li><strong>Model Answer:</strong> "True"</li>
                                <li><strong>Scoring:</strong> This factually incorrect response will receive negative points.</li>
                            </ul>
                        </li>
                    </ul>
                </li>
            </ol>
        </section>

        <section>
            <h2>Rules and Participation Requirements</h2>
            <ol>
                <li>
                    <strong>Submission Format:</strong>
                    <ul>
                        <li>Participants are not required to submit their models. However, they must submit the evaluation metrics generated using the official script provided by the organizers.</li>
                        <li>Submissions must include:
                            <ul>
                                <li>The evaluation metrics output from the provided script.</li>
                                <li>A detailed description of their approach, including the methods, training data, configurations, and techniques used to achieve the results.</li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li>
                    <strong>Model Transparency:</strong>
                    <ul>
                        <li>Participants are required to provide clear documentation about:</li>
                        <ul>
                            <li>The methods and techniques used, including any training data, preprocessing steps, fine-tuning strategies, and specific algorithms.</li>
                            <li>Any prompts, prompt engineering, or inference strategies employed.</li>
                        </ul>
                        <li>This information will be used to ensure transparency and promote openness within the competition but will not affect leaderboard rankings.</li>
                    </ul>
                </li>
                <li>
                    <strong>Training and Data Use:</strong>
                    <ul>
                        <li>Participants are free to use any methods, models, or data sources to achieve the best results.</li>
                        <li>There are no restrictions on the choice of training data, models, or tools. Participants can combine datasets, use proprietary or private data, and leverage any strategies or algorithms to maximize performance.</li>
                        <li><strong>Responsibility:</strong> Participants must ensure their approach complies with all applicable legal and ethical standards regarding data usage and methodology.</li>
                    </ul>
                </li>
                <li>
                    <strong>Submission Limits:</strong>
                    <ul>
                        <li>Each participant or team may submit a maximum of three sets of evaluation metrics for consideration on the leaderboard.</li>
                        <li>Each submission must reflect a distinct system or approach.</li>
                    </ul>
                </li>
                <li>
                    <strong>Leaderboard Ranking:</strong>
                    <ul>
                        <li>Submissions will be ranked on the official leaderboard based solely on the evaluation metrics generated by the provided script.</li>
                        <li>The leaderboard will reflect scores based on exact matches, semantic matches, partial matches, and penalize factually incorrect responses.</li>
                        <li>No distinction will be made between submissions using public or proprietary methods in the rankings. All valid submissions will appear on the leaderboard based on their scores.</li>
                    </ul>
                </li>
                <li>
                    <strong>Use of ClinIQLink Dataset:</strong>
                    <ul>
                        <li>The fully annotated ClinIQLink dataset will be released publicly for participants to use. However, its use is optional.</li>
                        <li>Participants may use the ClinIQLink dataset, external datasets, or any combination thereof to achieve the best results.</li>
                        <li>Evaluation must be conducted using the official script provided to ensure consistency in scoring.</li>
                    </ul>
                </li>
                <li>
                    <strong>Evaluation Requirements:</strong>
                    <ul>
                        <li>Participants are required to use the official evaluation script provided by the organizers to generate their metrics.</li>
                        <li>Submissions must strictly adhere to the output format specified by the script to ensure comparability across all entries.</li>
                    </ul>
                </li>
            </ol>
        </section>

        <section>
            <h2>Timeline</h2>
            <p>Timeline for BioNLP Workshop at ACL 2025:</p>
            <ul>
                <li>January 1, 2025: First Call for Participation</li>
                <li>February 15, 2025: Release of Testing Dataset and Testing Framework</li>
                <li>March 18, 2025: System Submission Deadline</li>
                <li>March 20, 2025: Papers Submission Deadline</li>
                <li>April 20, 2025: Notification of Acceptance</li>
                <li>May 20, 2025: Camera Ready Papers Due</li>
                <li>July 7, 2025: Pre-recorded Video Due</li>
                <li>July 31, 2025: BioNLP Workshop Date (at ACL 2025)</li>
            </ul>
            <img src="Images/Timeline.png" alt="Timeline" style="width:100%; margin-top:20px;">
        </section>

        <section>
            <h2>Research Directions</h2>
            <p>See the following survey papers for ideas on research directions:</p>
            <ul>
                <li>
                    <strong>Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models</strong><br>
                    <a href="https://arxiv.org/abs/2309.01219">https://arxiv.org/abs/2309.01219</a>
                </li>
                <li>
                    <strong>Survey of Hallucination in Natural Language Generation</strong><br>
                    <a href="https://dl.acm.org/doi/full/10.1145/3571730?casa_token=4qvgx-DzJjkAAAAA%3AOwIpns22iVZpou0ArNv0kCCt6_UXCKxivtJtN7V6YdMkX0VfeuNUG6aKi0mmdCblaZPPj75X_-46oQ">https://dl.acm.org/doi/full/10.1145/3571730</a>
                </li>
                <li>
                    <strong>A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions</strong><br>
                    <a href="https://arxiv.org/abs/2311.05232">https://arxiv.org/abs/2311.05232</a>
                </li>
                <li>
                    <strong>A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models</strong><br>
                    <a href="https://arxiv.org/abs/2401.01313">https://arxiv.org/abs/2401.01313</a>
                </li>
                <li>
                    <strong>Hallucination of Multimodal Large Language Models: A Survey</strong><br>
                    <a href="https://arxiv.org/abs/2404.18930">https://arxiv.org/abs/2404.18930</a>
                </li>
                <li>
                    <strong>A Survey of Hallucination in Large Foundation Models</strong><br>
                    <a href="https://arxiv.org/abs/2309.05922">https://arxiv.org/abs/2309.05922</a>
                </li>
                <li>
                    <strong>A Survey on Hallucination in Large Vision-Language Models</strong><br>
                    <a href="https://arxiv.org/abs/2402.00253">https://arxiv.org/abs/2402.00253</a>
                </li>
                <li>
                    <strong>TruthfulQA: Measuring How Models Mimic Human Falsehoods</strong><br>
                    <a href="https://arxiv.org/pdf/2109.07958">https://arxiv.org/pdf/2109.07958</a>
                </li>
                <li>
                    <strong>TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space</strong><br>
                    <a href="https://arxiv.org/pdf/2402.17811">https://arxiv.org/pdf/2402.17811</a>
                </li>
                <li>
                    <strong>The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models</strong><br>
                    <a href="https://arxiv.org/pdf/2401.03205">https://arxiv.org/pdf/2401.03205</a>
                </li>
            </ul>
        </section>

        <section>
            <h2>Support and FAQs</h2>
            <p>Coming soon</p>
        </section>

        <section>
            <h2>Result Reporting and Post-task Analysis</h2>
            <p>Coming Soon</p>
        </section>
        <section>
            <h2>Contact</h2>
            <p><strong>Brandon Colelough</strong></p>
            <p>Email: <a href="mailto:brandon.colelough@nih.giv">brandon.colelough@nih.giv</a></p>
        </section>
        <section>
            <h2>Conclusion</h2>
            <p>The LLM Lie Detector Test using Knowledge Retrieval is aimed at evaluating the factual accuracy of generative models, particularly in the medical domain. Participants will be provided a comprehensive framework with atomic question-answer pairs and well-defined evaluation metrics. This task focuses on the retrieval of accurate, precise information, without assessing the model’s reasoning or commonsense capabilities. Participants are expected to develop models that can reliably provide factually grounded answers to medical queries, and the competition will reward exact matches, semantic equivalents, and penalize factually incorrect or hallucinated responses. The task prioritizes transparency in model submissions, ensuring reproducibility and integrity.</p>
        </section>
    </main>
    <footer>
        <p>&copy; 2025 LLM Lie Detector Task. All rights reserved.</p>
    </footer>
</body>
</html>
